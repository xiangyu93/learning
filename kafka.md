# kafka #
## 生产者 ##
### 发送消息的方式

1. 发送并忘记
2. 同步发送
3. 异步发送

### 生产者重要的配置

1. acks

   指定必须要有多少个分区副本收到消息，生产者才会任务消息是写入成功的

   acks=0，生产者在成功写入消息之前不会等待任何来自服务器的响应

   acks=1，只要集群的首领节点收到消息，生产者就回收到一个来自服务器的成功响应

   acks=all，只有当所有参与复制的节点全部收到消息是，生产者才会收到一个来自服务器成功的响应。最安全的模式，延时会变高。

2. buffer.memory

   用来设置生产者内存缓冲区的大小，生产者用它缓冲要发送到服务器的消息，如果应用程序发送消息的速度超过发送到服务器的速度，会导致生产者空间不足。这个时候会，send方法要么被阻塞，要么抛出异常，取决于如何设置block.on.buffer.full参数（在0.9版本被替换成max.block.ms，表示在抛出异常之前可以阻塞一段时间）

3. compressio.type

   默认情况下，发送消息是不会雅座，改参数可以设置为snappy、gzip或lz4.

4. retries

   指定生产者在接收到服务器临时错误时，可以重发消息的次数。默认情况下，生产者会在每次重试之间等待100ms，可以通过retry.backoff.ms参数来改变这个时间间隔

5. batch.size

   当有多个消息被发送到同一个分区时，生产者会把他们放在同一个批次里。该参数指定了一个批次可以使用的内存大小。按字节极端（而不是消息个数）。当批次被填满，批次里的所有消息会被发送出去。不过生产者并不一定都会等到批次被填满才发生，半批次甚至只包含一个消息的批次也可能会发送，所以就算把批次设置得很大，也不会造成延迟，只是会占用更多的内存而已，单如果设置得太小，因为生产者需要频繁地发送消息，会增加一些额外的开销。

6. linger.ms

   该参数指定了生产者在发生批次之前等待更多消息加入批次的时间

7. max.in.fliget.requests.per.connection

   该参数指定了生产者在收到服务器响应之前可以发送多少个消息，他的值预告，就回占用雨多的内存，不过也会提升吞吐量。把他设置为1可以保证消息是安装发送的顺序写入服务器的，即使发生了重试。

8. timeout.ms，request.timeout.ms和metadata.fetch.timeout.ms

   request.timeout.ms指定了生产者在发生数据时等待服务器返回响应的时间。metadata.fetch.timeout.ms指定了生产者在获取元数据时等待服务器的时间。timeout.ms指定了broker等待同步副本返回消息确认的时间，与asks的配置相匹配--如果再指定时间内没有收到同步副本的确认，那么broker就会返回一个错误。

9. max.block.ms

   该参数指定了在调用send方法或使用partitionsFor方法获取元数据时，生产者阻塞时间。

10. max.request.size

    该参数用于控制生产者发送的请求大小。他可以指能发送的单个消息的最大值，也可以只单个请求里消息总的大小。

11. receive.buffer.bytes和send.buffer.bytes

    这两个参数分别指定了TCP socke接收和发送数据包的缓冲区大小，如果他们被设置为-1就使用操作系统的默认值。



### 顺序保证

kafka可以保证在统一分区里的消息是有序的。如果把retries参数设置为非零证书，同时把max.in.flight.requests.per.connection设为比1大的数，那么如果第一批消息写入失败，而第二批消息写入成功，broker会重试写入第一批消息，如果此时第一批也写入成功，那么两个消息的顺序就反过来了。

可以把max.in.flight.requests.per.connection设为1，retries设为大于0的整数，这样生产者尝试发送第一批次消息是，就不会有其他消息发送给broker，从而保证有序。

## 消费者

### 消费者、消费者组、分区的关系

消费者属于消费者组，一个分区只能被消费者组内的一个消费者消费

### 分配分区的过程

当消费者要加入群组时，他会向群组协调器发送一个joinGroup的请求，第一个加入群组的消费者将成为“群主”，群主从协调器那里获得群组成员列表（列表中包含了所有最近发送过心跳的消费者，他们被认为是活跃的），并负责给每一个消费者分配分区。它使用一个实现了PartitionAssignor接口的类来决定哪些分区应该被分配给哪个消费者。

kafka提供了两种分配策略，分配完毕之后，群主把分配情况列表发送给群组协调器，协调器再把这些信息发送给所有消费者。每个消费者只能看到自己的分配信息，只有群主知道知道群组内所有消费者的分配信息。这个过程会在每次再均衡时重复发生。

### 重要的配置

1. fetch.min.bytes

   该属性指定了消费者从服务器获取记录的最小字节数，

2. fetch.max.wait.ms

   用于指定broker的等待时间，默认500ms。如果fetch.max.wait.ms为100ms，并且fetch.min.bytes被设为1M，那么kafka在收到消费者的请求后，要么返回1M数据，要么在100ms后返回所有可用的数据，就看那个条件先得到满足。

3. max.partition.fetch.bytes

   改属性指定了服务器从每个分区里返回给消费者的最大字节数，他的默认值是1M。max.partition.fetch.bytes的值必须必broker能够接收的最大消息字节数（通过max.message.size属性配置）大，否则消费者可能无法读取这些信息，导致消费者一直挂起重试。

4. session.timeout.ms

   该属性指定了消费者在被认为死亡之前可以与服务器断开连接的时间，默认3s。该属性与heartbeat.interval.ms紧密相关。heartbeat.interval.ms指定了poll方法向协调器发送心跳的频率，session.timeout.ms则指定了可以消费者可以多久不发生信息。

5. auto.offset.reset

   该属性指定了消费者在读取到一个没有偏移量的分区或者偏移量无效该作何处理，默认值是latest

6. enable.auto.commint

   提交偏移量的方式，默认为true，自动提交偏移量，如果设置为true，还可以通过配置auto.commit.interval.ms来控制提交的频率。

7. partition.assignment.stratgegy

   分区分配策略，Range和RoundRobin

   Range：会把若干连续分区分配给消费者

   RoundRobin：会把分区逐个分配给消费者

8. max.poll.records

   该属性用于控制单次调用call方法能够返回的记录数量，可以帮你控制在轮训里需要处理的数据量。

9. receive.buffer.bytes和send.buffer.bytes

   socket在读写数据是用到的TCP缓冲区大小。如果为-1，则使用系统默认值。

### 提交和偏移量

更新分区当前位置的操作叫提交

提交偏移量：消费者王一个叫_consumer_offset的主题发送消息，消息里包含每个分区的偏移量。

1. 自动提交

   enable.auto.commit为true，在时间间隔auto.commit.interval.ms被提交，默认值5s。

2. 提交当前偏移量

   enable.auto.commit设为false，让应用程序决定何时提交偏移量。使用commitSync()函数

3. 异步提交

   enable.auto.commit设为false。使用commitASync函数，支持回调。

4. 同步和异步组合提交

5. 提交特定偏移量

### 独立消费者--为什么以及怎样使用没有群组的消费者

一个消费者可以订阅主题（并加入消费者群组），或者为自己分配分区，但不能同时做这两件事情。

当消费者为自己分配分区后，如果主题新增了分区，那么消费者则不会受到来自这个分区的消息，除非程序周期性检测是否有新分区加入，要么在添加分区后重启应用程序。

## 集群

### 成员

需要为kafka的成员指定一个唯一id，成员会把自己的id注册到zk的/brokers/ids路径下。kafka组件监听/brokers/ids路径，当有成员上下线时，这些组件都会获得通知。

### 控制器

就是一个broker，除了具有一般broker的功能之外，还复制分区首领的选举。集群里第一个启动的broker通过在zk里创建一个临时节点/controller让自己成为控制器，其他控制器则在控制器节点上创建watch对象，监听这个节点变更。

### 复制

每个主题被分为若干分区，每个分区有多个副本。那些副本被保存在broker上，每个broker可以保存成百上千个属于不同主题和分区的副本。

副本类型：

1. 首领副本

   每个分区都有一个首领副本。为了保证一致性，所有生产者请求和消费者请求都会经过这个副本。

2. 跟随者副本

   首领副本以外的副本都是跟随者副本。跟随者副本会在有新消息到达时尝试从首领那里复制消息。

   持续请求得到的最新消息副本被称为同步副本。在首领发生失效时，只有同步副本才有可能被选为首领。

   首选首领：创建主题时选定的首领就是分区的首选首领。默认情况下，kafka的auto.leader.rebalcance.enable设为true是，他会检测首选首领是否是当前首领，如果不是，并且该副本是同步副本，则会触发首领选举，让首选首领称为当前首领。

### kafka零复制

kafka使用零复制技术向客户端发送消息--kafka直接把消息从文件（或者更确切的说是Linux文件系统缓存）里发送到网络通道，而不需要经过任何中间缓冲区。

### 墓碑消息

键不为null，值为null的消息，清理线程发现该消息时，会先进行常规清理，只保留值为null的消息。该消息会被保留一段时间，时间长短可配置。



